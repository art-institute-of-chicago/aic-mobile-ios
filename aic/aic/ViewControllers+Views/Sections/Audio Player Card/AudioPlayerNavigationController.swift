//
//  AudioPlayerNavigationController.swift
//  aic
//
//  Created by Filippo Vanucci on 2/2/18.
//  Copyright Â© 2018 Art Institute of Chicago. All rights reserved.
//

import UIKit
import AVFoundation
import MediaPlayer
import Alamofire
import Kingfisher

protocol AudioPlayerNavigationControllerDelegate: class {
	func audioPlayerDidStartPlaying(audio: AICAudioFileModel)
	func audioPlayerDidPause(audio: AICAudioFileModel)
	func audioPlayerDidFinishPlaying(audio: AICAudioFileModel)
}

class AudioPlayerNavigationController: CardNavigationController {
	var audioInfoVC: AudioInfoViewController = AudioInfoViewController()
	let miniAudioPlayerView: MiniAudioPlayerView = MiniAudioPlayerView()

	weak var sectionDelegate: AudioPlayerNavigationControllerDelegate?

	let remoteSkipTime: Int = 10 // Number of seconds to skip forward/back with MPRemoteCommandCenter seek

	// AVPlayer
	fileprivate let avPlayer = AVPlayer()
	private var audioProgressTimer: Timer?
	private var audioPlayerProgressTimer: Timer?

	// Audio
	var currentAudioFile: AICAudioFileModel?
	var currentAudioFileMaxProgress: CGFloat = 0
	var selectedLanguage: Common.Language?

	// Info
	var currentTourLanguage: Common.Language = .english
	var currentTourStopAudioFile: AICAudioFileModel?
	var currentAudioBumper: AICAudioFileModel?
	var previousTrackTitle: String = ""
	var currentTrackTitle: String = "" {
		didSet {
			previousTrackTitle = oldValue
		}
	}
	var currentImageURL: URL?

	// Analytics data
	var analyticsSource: AICAnalytics.PlaybackSource = .AudioGuide
	var analyticsArtwork: AICObjectModel?
	var analyticsTour: AICTourModel?

	var autoPlay: Bool = false

	var isUpdatingObjectViewProgressSlider = false

	// Audio Guide Number (track it to log analytics when loading fails)
	var audioGuideNumber: Int?

	override func viewDidLoad() {
		super.viewDidLoad()

		// Set Close State as MiniPlayer
		closedState = .mini_player

		miniAudioPlayerView.frame.origin = CGPoint.zero
		miniAudioPlayerView.frame.size = CGSize(width: UIScreen.main.bounds.width, height: Common.Layout.miniAudioPlayerHeight)

		audioInfoVC.view.frame.origin = CGPoint(x: 0, y: contentTopMargin)
		audioInfoVC.view.frame.size = CGSize(width: UIScreen.main.bounds.width, height: Common.Layout.cardContentHeight + Common.Layout.tabBarHeight - contentTopMargin)

		// Add main VC as subview to rootVC
		audioInfoVC.willMove(toParent: rootVC)
		rootVC.view.addSubview(audioInfoVC.view)
		audioInfoVC.didMove(toParent: rootVC)

		// Add subviews
		rootVC.view.addSubview(miniAudioPlayerView)

		// Related Tours Link
		audioInfoVC.relatedToursView.bodyTextView.delegate = self

		// Language Selector Delegate
		audioInfoVC.languageSelector.delegate = self

		// Mini Player Tap and Close Events
		let miniAudioPlayerTap = UITapGestureRecognizer(target: self, action: #selector(miniAudioPlayerTapped))
		miniAudioPlayerView.addGestureRecognizer(miniAudioPlayerTap)

		miniAudioPlayerView.closeButton.addTarget(self, action: #selector(miniAudioPlayerCloseButtonPressed(button:)), for: .touchUpInside)

		// Audio Player Slider
		audioInfoVC.audioPlayerView.slider.addTarget(self, action: #selector(audioPlayerSliderValueChanged(slider:)), for: .valueChanged)
		audioInfoVC.audioPlayerView.slider.addTarget(self, action: #selector(audioPlayerSliderStartedSliding(slider:)), for: .touchDown)
		audioInfoVC.audioPlayerView.slider.addTarget(self, action: #selector(audioPlayerSliderFinishedSliding(slider:)), for: [.touchUpInside, .touchUpOutside, .touchCancel]
		)

		// Play/Pause Button
		miniAudioPlayerView.playPauseButton.addTarget(self, action: #selector(playPauseButtonPressed(button:)), for: .touchUpInside)
		audioInfoVC.audioPlayerView.playPauseButton.addTarget(self, action: #selector(playPauseButtonPressed(button:)), for: .touchUpInside)

		// AV Session
		configureAVAudioSession()
		NotificationCenter.default.addObserver(self, selector: #selector(configureAVAudioSession), name: AVAudioSession.routeChangeNotification, object: nil)

		// Accessibility
		downArrowButton.accessibilityLabel = "Close Audio Player"
		closeButton.accessibilityLabel = "Close Audio Player"
	}

	override func viewDidAppear(_ animated: Bool) {
		super.viewDidAppear(animated)

		// Set as
		self.becomeFirstResponder()
		UIApplication.shared.beginReceivingRemoteControlEvents()
		initializeMPRemote()
	}

	// Progress Bar Color

	func setProgressBarColor(color: UIColor) {
		miniAudioPlayerView.setProgressBarColor(color: color)
	}

	// MARK: Play Audio

	func playArtworkAudio(artwork: AICObjectModel, audio: AICAudioFileModel, source: AICAnalytics.PlaybackSource, audioGuideNumber: Int? = nil) {
		currentAudioBumper = nil
		currentTourStopAudioFile = nil

		currentTrackTitle = artwork.title
		currentImageURL = artwork.imageUrl

		self.autoPlay = true

		self.audioGuideNumber = audioGuideNumber

		if load(audioFile: audio, coverImageURL: artwork.imageUrl as URL) {
			miniAudioPlayerView.reset()
			audioInfoVC.setArtworkContent(artwork: artwork, audio: audio)
		}

		// Log analytics
		AICAnalytics.sendAudioPlayedEvent(source: source,
										  language: audio.language,
										  audio: audio,
										  artwork: artwork,
										  tour: nil)
		analyticsSource = source
		analyticsArtwork = artwork
		analyticsTour = nil
	}

	func playTourOverviewAudio(tour: AICTourModel, source: AICAnalytics.PlaybackSource) {
		currentTourLanguage = tour.language

		let nextTourStop = tour.stops.first!
		setAudioBumperFor(nextTourStop: nextTourStop)

		currentTourStopAudioFile = tour.audioCommentary.audioFile

		currentTrackTitle = tour.title
		currentImageURL = tour.imageUrl

		self.autoPlay = true

		self.audioGuideNumber = nil

		// set correct language on audio
		var audio = tour.audioCommentary.audioFile
		audio.language = tour.language

		if load(audioFile: audio, coverImageURL: tour.imageUrl as URL) {
			miniAudioPlayerView.reset()
			audioInfoVC.setTourContent(tour: tour)
		}

		// Log analytics
		AICAnalytics.sendAudioPlayedEvent(source: source,
										  language: tour.language,
										  audio: audio,
										  artwork: nil,
										  tour: tour)
		analyticsSource = source
		analyticsArtwork = nil
		analyticsTour = tour
	}

	func playTourStopAudio(tourStop: AICTourStopModel, tour: AICTourModel) {
		currentTourLanguage = tour.language

		if let stopIndex = tour.getIndex(forStopObject: tourStop.object) {
			if stopIndex + 1 < tour.stops.count {
				setAudioBumperFor(nextTourStop: tour.stops[stopIndex + 1])
			}
		}

		currentTourStopAudioFile = tourStop.audio

		currentTrackTitle = tourStop.object.title
		currentImageURL = tourStop.object.imageUrl

		self.autoPlay = true

		self.audioGuideNumber = nil

		// set correct language on audio
		var audio = tourStop.audio
		audio.language = tour.language

		if currentAudioFile?.nid == audio.nid {
			if miniAudioPlayerView.playPauseButton.isSelected {
				_ = pause()
			} else {
				_ = play()
			}
		} else {
			if load(audioFile: audio, coverImageURL: tourStop.object.imageUrl as URL) {
				miniAudioPlayerView.reset()
				audioInfoVC.setArtworkContent(artwork: tourStop.object, audio: audio, tour: tour)
			}
		}

		// Log analytics
		AICAnalytics.sendAudioPlayedEvent(source: .TourStop,
										  language: tour.language,
										  audio: tourStop.audio,
										  artwork: tourStop.object,
										  tour: tour)
		analyticsSource = .TourStop
		analyticsArtwork = tourStop.object
		analyticsTour = tour
	}

	private func setAudioBumperFor(nextTourStop: AICTourStopModel) {
		currentAudioBumper = nil
		if let audioBumper = nextTourStop.audioBumper {
			if audioBumper.availableLanguages.contains(self.currentTourLanguage) {
				currentAudioBumper = nextTourStop.audioBumper
				currentAudioBumper!.language = self.currentTourLanguage
			}
		}
	}

	private func playAudioBumper(audioBumper: AICAudioFileModel) {
		self.audioGuideNumber = nil

		if load(audioFile: audioBumper, coverImageURL: self.currentImageURL!) {
		}
	}

	// MARK: Load Audio

	private func load(audioFile: AICAudioFileModel, coverImageURL: URL) -> Bool {

		if let previousAudioFile = currentAudioFile {
			// If it's a new artwork, log analytics
			if audioFile.nid != previousAudioFile.nid {
				// Log analytics
				// GA only accepts int values, so send an int from 1-100
				let pctComplete = Int(currentAudioFileMaxProgress * 100)
				AICAnalytics.sendAudioStoppedEvent(title: previousTrackTitle, audio: previousAudioFile, percentPlayed: pctComplete)
			}
				// If it's same nid and language, don't load audio
			else if selectedLanguage == nil {
				return false
			}
		}

		self.currentAudioFile = audioFile
		self.currentAudioFileMaxProgress = 0

		// even if the player defaults to a language
		// check to see if the user changed it
		if selectedLanguage != nil {
			currentAudioFile!.language = selectedLanguage!
		}

		// Clear out current player
		audioPlayerProgressTimer?.invalidate()

		// Reset visuals
		miniAudioPlayerView.resetProgress()
		audioInfoVC.audioPlayerView.resetProgress()

		// Set the player view to show loading status
		showLoadingMessage()

		// Load the file
		let asset = AVURLAsset(url: currentAudioFile!.url)
		asset.loadValuesAsynchronously(forKeys: ["tracks"]) {
			let error: NSErrorPointer = nil
			let status = asset.statusOfValue(forKey: "tracks", error: error)

			// Make sure we're on the main thread for UI Updates (alert, timer, etc.)
			DispatchQueue.main.async(execute: {
				switch status {
				case .failed, .cancelled:
					self.showLoadError(forAudioFile: audioFile, coverImageURL: coverImageURL)
					break

				case .loaded:
					// Create Audio Player
					let playerItem = AVPlayerItem(asset: asset)
					NotificationCenter.default.addObserver(self, selector: #selector(AudioPlayerNavigationController.audioPlayerDidFinishPlaying(_:)), name: NSNotification.Name.AVPlayerItemDidPlayToEndTime, object: playerItem)

					// Set the item as our player's current item
					self.avPlayer.replaceCurrentItem(with: playerItem)

					// Show the audio file
					self.showAudioControls()

					// Create NSTimer to check for audio update progress and update as needed
					if self.audioProgressTimer == nil {
						self.audioPlayerProgressTimer = Timer.scheduledTimer(timeInterval: 0.25,
																			 target: self,
																			 selector: #selector(AudioPlayerNavigationController.updateAudioPlayerProgress),
																			 userInfo: nil,
																			 repeats: true
						)
					}

					// Retrieve cover image
					KingfisherManager.shared.retrieveImage(with: ImageResource(downloadURL: coverImageURL, cacheKey: coverImageURL.absoluteString), options: KingfisherManager.shared.defaultOptions, progressBlock: nil, completionHandler: { (result) in
						guard let result = try? result.get() else {
							self.audioInfoVC.imageView.image = nil
							return
						}

						self.setMediaInformation(image: result.image)
					})

					// Auto-play on load
					if self.autoPlay == true {
						_ = self.play()
					}

					break

				default:
					print("Unknown error")
				}
			})
		}

		return true
	}

	private func setMediaInformation(image: UIImage) {
		// MPMediaItemPropertyArtwork
		let artworkMediaItem = MPMediaItemArtwork.init(boundsSize: image.size, requestHandler: { (_) -> UIImage in
			return image
		})

		// Set the MPNowPlaying information
		let songInfo: [String: AnyObject] = [
			MPMediaItemPropertyTitle: NSString(string: self.currentTrackTitle),
			MPMediaItemPropertyArtist: NSString(string: "Art Institute of Chicago"),
			MPMediaItemPropertyArtwork: artworkMediaItem,
			MPMediaItemPropertyPlaybackDuration: NSNumber(floatLiteral: (CMTimeGetSeconds(self.avPlayer.currentItem!.asset.duration))),
			MPMediaItemPropertyAlbumTrackCount: NSNumber(floatLiteral: 0),
			MPNowPlayingInfoPropertyPlaybackQueueIndex: NSNumber(floatLiteral: 0),
			MPNowPlayingInfoPropertyPlaybackQueueCount: NSNumber(floatLiteral: 0),
			MPNowPlayingInfoPropertyPlaybackRate: NSInteger(1.0) as AnyObject
		]

		MPNowPlayingInfoCenter.default().nowPlayingInfo = songInfo
	}

	private func showLoadError(forAudioFile audioFile: AICAudioFileModel, coverImageURL: URL) {
		// Present a UIAlertView that allows the user to try to load the file.
		let alertView = UIAlertController(title: "audio_player_load_failure_title".localized(using: "MediaUI"), message: "audio_player_load_failure_body".localized(using: "MediaUI"), preferredStyle: .alert)

		// Retry Action
		alertView.addAction(UIAlertAction(title: "audio_player_load_failure_retry_action".localized(using: "MediaUI"), style: .default, handler: { (_) -> Void in
			self.currentAudioFile = nil
			_ = self.load(audioFile: audioFile, coverImageURL: coverImageURL)
		}))

		// Cancel Action
		alertView.addAction(UIAlertAction(title: "global_cancel_action".localized(using: "Base"), style: .cancel, handler: { (_) -> Void in
			self.hide()
		}))

		self.present(alertView, animated: true, completion: nil)

		// Log Analytics
		AICAnalytics.sendErrorAudioLoadFailEvent(number: audioFile.nid)
	}

	// Set the loading status as the track title
	private func showLoadingMessage() {
		let localizedLoadingMessage = "audio_player_loading".localized(using: "MediaUI")
		miniAudioPlayerView.showLoadingMessage(message: localizedLoadingMessage)
		audioInfoVC.showLoadingMessage(message: localizedLoadingMessage)
	}

	private func showAudioControls() {
		miniAudioPlayerView.showTrackTitle(title: self.currentTrackTitle)
		audioInfoVC.showTrackTitle(title: self.currentTrackTitle)
	}

	// MARK: Audio Playback

	@objc internal func configureAVAudioSession() {
		do {
			// Determine playback category based on bluetooth connection to avoid HFP playback through A2DP headphones
			let bluetoothConnected = AVAudioSession
				.sharedInstance()
				.currentRoute
				.outputs
				.filter {
					$0.portType == .bluetoothA2DP || $0.portType == .bluetoothHFP
			}
			.first != nil
			let playbackCategory = bluetoothConnected ? AVAudioSession.Category.playback : AVAudioSession.Category.playAndRecord

			// Init session with correct category
			try AVAudioSession.sharedInstance().setCategory(playbackCategory, options: .allowBluetooth)
			try AVAudioSession.sharedInstance().setActive(true)
		} catch {
			print("Could not initialize audio session")
		}
	}

	private func initializeMPRemote() {
		MPRemoteCommandCenter.shared().previousTrackCommand.isEnabled = false
		MPRemoteCommandCenter.shared().seekBackwardCommand.isEnabled = false

		MPRemoteCommandCenter.shared().nextTrackCommand.isEnabled = false
		MPRemoteCommandCenter.shared().seekForwardCommand.isEnabled = false

		// You must also register for any other command in order to take control
		// of the command center, or else disabling other commands does not work.
		// For example:
		MPRemoteCommandCenter.shared().playCommand.isEnabled = true
		MPRemoteCommandCenter.shared().playCommand.addTarget { (_) -> MPRemoteCommandHandlerStatus in
			return self.play()
		}

		MPRemoteCommandCenter.shared().pauseCommand.isEnabled = true
		MPRemoteCommandCenter.shared().pauseCommand.addTarget { (_) -> MPRemoteCommandHandlerStatus in
			return self.pause()
		}

		MPRemoteCommandCenter.shared().skipForwardCommand.isEnabled = true
		MPRemoteCommandCenter.shared().skipForwardCommand.preferredIntervals = [NSNumber(value: remoteSkipTime)]
		MPRemoteCommandCenter.shared().skipForwardCommand.addTarget { (_) -> MPRemoteCommandHandlerStatus in
			return self.skipForward()
		}

		MPRemoteCommandCenter.shared().skipBackwardCommand.isEnabled = true
		MPRemoteCommandCenter.shared().skipBackwardCommand.preferredIntervals = [NSNumber(value: remoteSkipTime)]
		MPRemoteCommandCenter.shared().skipBackwardCommand.addTarget { (_) -> MPRemoteCommandHandlerStatus in
			return self.skipBackward()
		}
	}

	@objc internal func play() -> MPRemoteCommandHandlerStatus {
		if let currentItem = avPlayer.currentItem {
			// If we are at the end, start from the beginning
			let currentTime = floor(CMTimeGetSeconds(currentItem.currentTime()))
			let duration = floor(CMTimeGetSeconds(currentItem.asset.duration))

			if duration < 1 {
				if let audio = currentAudioFile {
					showLoadError(forAudioFile: audio, coverImageURL: currentImageURL!)
				}
				return .success
			}

			if currentTime >= duration {
				currentItem.seek(to: CMTime(seconds: 0.0, preferredTimescale: avPlayer.currentItem!.duration.timescale))
			}

			// Play
			avPlayer.play()
			synchronizePlayPauseButtons(isPlaying: true)
			if let currentAudioFile = currentAudioFile {
				sectionDelegate?.audioPlayerDidStartPlaying(audio: currentAudioFile)
			}

			// Enable proximity sensing, needed when user is holding phone to their ear to listen to audio
			UIDevice.current.isProximityMonitoringEnabled = true

			return .success
		}
		return .commandFailed
	}

	@objc internal func pause() -> MPRemoteCommandHandlerStatus {
		if avPlayer.currentItem != nil {
			avPlayer.pause()
			synchronizePlayPauseButtons(isPlaying: false)

			if var info = MPNowPlayingInfoCenter.default().nowPlayingInfo {
				info[MPNowPlayingInfoPropertyPlaybackRate] = NSInteger(0.0)
				MPNowPlayingInfoCenter.default().nowPlayingInfo = info
			}

			if let currentAudioFile = self.currentAudioFile {
				sectionDelegate?.audioPlayerDidPause(audio: currentAudioFile)
			}

			// Enable proximity sensing, needed when user is holding phone to their ear to listen to audio
			UIDevice.current.isProximityMonitoringEnabled = false
			return .success
		}
		return .commandFailed
	}

	internal func seekToTime(_ timeInSeconds: Double) {
		if let currentItem = avPlayer.currentItem {
			currentItem.seek(to: CMTime(seconds: timeInSeconds, preferredTimescale: currentItem.duration.timescale))
			updateAudioPlayerProgress()
		}
	}

	@objc internal func skipForward() -> MPRemoteCommandHandlerStatus {
		if let currentItem = avPlayer.currentItem {
			let duration = CMTimeGetSeconds(currentItem.duration)
			let currentTime = CMTimeGetSeconds(avPlayer.currentTime())
			var skipTime = currentTime + Double(remoteSkipTime)

			if skipTime > duration {
				skipTime = duration
			}

			seekToTime(skipTime)
			return .success
		}
		return .commandFailed
	}

	@objc internal func skipBackward() -> MPRemoteCommandHandlerStatus {
		if avPlayer.currentItem != nil {
			let currentTime = CMTimeGetSeconds(avPlayer.currentTime())
			var skipTime = currentTime - Double(remoteSkipTime)
			if skipTime < 0 {
				skipTime = 0
			}

			seekToTime(skipTime)
			return .success
		}
		return .commandFailed
	}

	fileprivate func synchronizePlayPauseButtons(isPlaying: Bool) {
		miniAudioPlayerView.playPauseButton.isSelected = isPlaying
		audioInfoVC.audioPlayerView.playPauseButton.isSelected = isPlaying
	}

	// MARK: Show/Hide Card

	override func showFullscreen() {
		super.showFullscreen()
		self.view.backgroundColor = .aicDarkGrayColor
		self.downArrowButton.alpha = 1.0
		self.miniAudioPlayerView.alpha = 0.0

		// Accessibility
		audioInfoVC.willMove(toParent: self)
		self.view.addSubview(audioInfoVC.view)
		audioInfoVC.didMove(toParent: self)
		self.view.accessibilityElementsHidden = false
		self.view.accessibilityElements = [
			downArrowButton,
			audioInfoVC.view
			]
			.compactMap { $0 }
	}

	override func showMiniPlayer() {
		super.showMiniPlayer()
		UIView.animate(withDuration: 0.25) {
			self.downArrowButton.alpha = 0.0
		}

		// Accessibility
		self.view.addSubview(miniAudioPlayerView)
		self.view.accessibilityElementsHidden = false
		self.view.accessibilityElements = [
			miniAudioPlayerView
		]
	}

	override func cardDidShowFullscreen() {
		// Log analytics
		AICAnalytics.trackScreenView("Audio Player", screenClass: "AudioPlayerNavigationController")

		// Accessibility
		downArrowButton.isAccessibilityElement = true
		miniAudioPlayerView.removeFromSuperview()
		UIAccessibility.post(notification: .screenChanged, argument: audioInfoVC.audioPlayerView.titleLabel)
	}

	override func cardWillShowMiniPlayer() {
		audioInfoVC.languageSelector.close()
	}

	override func cardDidShowMiniPlayer() {
		UIView.animate(withDuration: 0.25) {
			self.miniAudioPlayerView.alpha = 1.0
		}
		UIView.animate(withDuration: 0.25, delay: 0.25, animations: {
			self.view.backgroundColor = .clear
		}, completion: nil)

		// Accessibility
		downArrowButton.isAccessibilityElement = false
		audioInfoVC.view.removeFromSuperview()
	}

	override func cardWillHide() {
		audioInfoVC.languageSelector.close()
	}

	override func cardDidHide() {
		currentAudioFile = nil

		// Accessibility
		self.view.accessibilityElementsHidden = true
		self.view.accessibilityElements = [
		]
	}
}

// Pan Gesture
extension AudioPlayerNavigationController {
	override internal func gestureRecognizer(_ gestureRecognizer: UIGestureRecognizer, shouldRecognizeSimultaneouslyWith otherGestureRecognizer: UIGestureRecognizer) -> Bool {
		if gestureRecognizer == cardPanGesture {
			if audioInfoVC.scrollView.contentOffset.y <= 0 {
				return true
			}
		}
		return false
	}
}

// MARK: Events

extension AudioPlayerNavigationController {
	// Received event from lock screen (remote control)
	override func remoteControlReceived(with event: UIEvent?) {
		// Make sure an audio file is loaded
		if avPlayer.currentItem != nil {
			// If it is, respond to event
			if event?.type == .remoteControl {
				switch (event?.subtype)! {

				// Play/Pause buttons
				case UIEventSubtype.remoteControlPlay:
					_ = play()
					break

				case UIEventSubtype.remoteControlPause:
					_ = pause()
					break

				// Headphone remote control toggle
				case UIEventSubtype.remoteControlTogglePlayPause:
					if avPlayer.rate != 0 && avPlayer.error == nil {
						_ = pause()
					} else {
						_ = play()
					}
					break
				default:
					break
				}
			}
		}
	}

	// Update the progress for the mini and regular audio players
	// every frame
	@objc internal func updateAudioPlayerProgress() {

		if avPlayer.currentItem != nil && avPlayer.currentItem?.status == .readyToPlay {
			let progress = CMTimeGetSeconds(avPlayer.currentTime())
			let duration = CMTimeGetSeconds(avPlayer.currentItem!.asset.duration)

			// Record the progress for analytics
			let pct = CGFloat(progress/duration)
			if pct > currentAudioFileMaxProgress {
				currentAudioFileMaxProgress = pct
			}

			// Update the progress bar views
			audioInfoVC.audioPlayerView.updateProgress(progress: progress, duration: duration, setSliderValue: !isUpdatingObjectViewProgressSlider)
			miniAudioPlayerView.updateProgress(progress: progress, duration: duration)

			// Update now playing with progress
			if var info = MPNowPlayingInfoCenter.default().nowPlayingInfo {
				info[MPNowPlayingInfoPropertyElapsedPlaybackTime] = NSInteger(progress)
				DispatchQueue.main.async {
					MPNowPlayingInfoCenter.default().nowPlayingInfo = info
				}
			}
		}
	}

	@objc internal func audioPlayerDidFinishPlaying(_ notification: Notification) {
		synchronizePlayPauseButtons(isPlaying: false)

		// Log analytics
		if let currentAudio = currentAudioFile {
			AICAnalytics.sendAudioStoppedEvent(title: currentTrackTitle, audio: currentAudio, percentPlayed: 100)
		}

		// check that we are playing tour stop audio, before you play bumper or original track
		if let currentAudio = currentAudioFile,
			let currentTourStopAudio = currentTourStopAudioFile,
			let currentBumper = currentAudioBumper {

			if currentAudio.nid == currentTourStopAudio.nid {
				// if you just played tour stop audio
				// play audio bumper if there is one
				self.autoPlay = true
				playAudioBumper(audioBumper: currentBumper)
			} else if currentAudio.nid == currentBumper.nid {
				self.autoPlay = false
				if load(audioFile: currentTourStopAudioFile!, coverImageURL: currentImageURL!) {
					miniAudioPlayerView.reset()
				}

				// notify end of audio playback
				self.sectionDelegate?.audioPlayerDidFinishPlaying(audio: currentTourStopAudio)
				// and hide
				if self.currentState != .fullscreen {
					hide()
				}
			}
		} else if let currentAudio = currentAudioFile {
			// notify end of audio playback
			self.sectionDelegate?.audioPlayerDidFinishPlaying(audio: currentAudio)
			// rewind to 0
			seekToTime(0.0)
			// and hide
			if self.currentState != .fullscreen {
				hide()
			}
		}
	}

	// Audio player Slider Events

	@objc internal func audioPlayerSliderStartedSliding(slider: UISlider) {
		// Stop the progress from updating, otherwise the two funcs fight
		isUpdatingObjectViewProgressSlider = true
	}

	@objc internal func audioPlayerSliderValueChanged(slider: UISlider) {
		if let currentItem = avPlayer.currentItem {
			let newTime = CMTimeGetSeconds(currentItem.asset.duration) * Double(audioInfoVC.audioPlayerView.slider.value)
			seekToTime(newTime)
			updateAudioPlayerProgress()
		}
	}

	@objc internal func audioPlayerSliderFinishedSliding(slider: UISlider) {
		isUpdatingObjectViewProgressSlider = false
		updateAudioPlayerProgress()
	}

	@objc internal func miniAudioPlayerCloseButtonPressed(button: UIButton) {

		// Log Analytics
		if let audio = currentAudioFile {
			if currentAudioFileMaxProgress < 1.0 {
				let pctComplete = Int(currentAudioFileMaxProgress * 100)
				AICAnalytics.sendAudioStoppedEvent(title: currentTrackTitle, audio: audio, percentPlayed: pctComplete)
			}
		}

		_ = pause()
		hide()
		currentAudioFile = nil
		// TODO: remove track from MPNowPlayingInfoCenter and RemoteControl
	}

	@objc internal func miniAudioPlayerTapped() {
		showFullscreen()
	}

	@objc internal func playPauseButtonPressed(button: UIButton) {
		// Play
		if button.isSelected == false {
			if avPlayer.currentItem?.duration == avPlayer.currentTime() {
				seekToTime(0)
			}
			_ = play()
		}
			// Pause
		else {
			_ = pause()
		}
	}
}

// MARK: LanguageSelectorViewDelegate

extension AudioPlayerNavigationController: LanguageSelectorViewDelegate {
	func languageSelectorDidSelect(language: Common.Language) {
		if let audio = currentAudioFile {
			selectedLanguage = language // set the language to indicate the language has been selected using the LanguageSelector
			if load(audioFile: audio, coverImageURL: currentImageURL!) {
				miniAudioPlayerView.reset()
				audioInfoVC.updateAudioContent(audio: currentAudioFile!)
			}
			selectedLanguage = nil

			// Log Analytics
			AICAnalytics.sendAudioPlayedEvent(source: analyticsSource,
											  language: language,
											  audio: audio,
											  artwork: analyticsArtwork,
											  tour: analyticsTour)
		}
	}
}

// MARK: Related Tours Link

extension AudioPlayerNavigationController: UITextViewDelegate {
	func textView(_ textView: UITextView, shouldInteractWith URL: URL, in characterRange: NSRange, interaction: UITextItemInteraction) -> Bool {
		if URL.absoluteString.range(of: "artic") != nil {
			_ = pause()
			showMiniPlayer()
			return true
		}
		return false
	}
}
